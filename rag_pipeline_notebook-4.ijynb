{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHXZdkSmrBcM"
      },
      "outputs": [],
      "source": [
        "def run_rag_pipeline(pdf_paths):\n",
        "    try:\n",
        "        # Initialize combined document storage\n",
        "        all_document_texts = []\n",
        "        all_document_ids = []\n",
        "        document_map = {}\n",
        "        current_doc_id = 0\n",
        "        document_sources = {}  # New: Track source PDF for each chunk\n",
        "\n",
        "        # Load and Chunk PDFs\n",
        "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
        "        for pdf_path in pdf_paths:\n",
        "            print(f'Processing PDF: {pdf_path}')\n",
        "            loader = PyPDFLoader(pdf_path)\n",
        "            documents = loader.load()\n",
        "            chunks = text_splitter.split_documents(documents)\n",
        "            document_texts = [chunk.page_content for chunk in chunks]\n",
        "            document_ids = [str(i + current_doc_id) for i in range(len(document_texts))]\n",
        "            document_map.update(dict(zip(document_ids, document_texts)))\n",
        "            # Track source PDF\n",
        "            source_name = os.path.basename(pdf_path).split('_')[0]  # e.g., 'QuantumCore' or 'NeoCompute'\n",
        "            document_sources.update({doc_id: source_name for doc_id in document_ids})\n",
        "            all_document_texts.extend(document_texts)\n",
        "            all_document_ids.extend(document_ids)\n",
        "            current_doc_id += len(document_texts)\n",
        "            print(f'Created {len(document_texts)} chunks from {pdf_path}')\n",
        "\n",
        "        print(f'Total chunks created: {len(all_document_texts)}')\n",
        "\n",
        "        # Load ColBERT Model\n",
        "        model_name = 'lightonai/GTE-ModernColBERT-v1'\n",
        "        model = models.ColBERT(model_name_or_path=model_name)\n",
        "\n",
        "        # Initialize Voyager Index\n",
        "        index_folder = 'pylate-index'\n",
        "        index_name = 'pdf_index'\n",
        "        index = indexes.Voyager(index_folder=index_folder, index_name=index_name, override=True)\n",
        "\n",
        "        # Create and Index Embeddings\n",
        "        documents_embeddings = model.encode(\n",
        "            all_document_texts,\n",
        "            batch_size=32,\n",
        "            is_query=False,\n",
        "            show_progress_bar=True\n",
        "        )\n",
        "        index.add_documents(all_document_ids, documents_embeddings=documents_embeddings)\n",
        "\n",
        "        # Initialize Retriever\n",
        "        retriever = retrieve.ColBERT(index=index)\n",
        "\n",
        "        # Initialize FLAN-T5 Generator\n",
        "        generator = pipeline('text2text-generation', model='google/flan-t5-base', max_length=300)\n",
        "\n",
        "        # Define Prompt Template\n",
        "        prompt_template = '''Using only the provided text, answer the user's question with a concise and accurate response. For questions about specific roles (e.g., CEO, CTO, CFO), return only the full name of the individual in that role. For questions about lists (e.g., products), return all items as a comma-separated list of names only. Exclude any details not directly relevant to the question, such as technical specifications, unless explicitly requested. If the answer is not in the text, respond with 'The answer could not be found in the text.'\n",
        "\n",
        "Text: {context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:''' \n",
        "        PROMPT = PromptTemplate(template=prompt_template, input_variables=['context', 'question'])\n",
        "\n",
        "        return model, index, retriever, generator, PROMPT, document_map, document_sources\n",
        "\n",
        "def query_rag(model, index, retriever, generator, PROMPT, document_map, document_sources, query):\n",
        "    try:\n",
        "        queries = [query]\n",
        "\n",
        "        # Encode Query\n",
        "        query_embedding = model.encode(\n",
        "            queries,\n",
        "            batch_size=32,\n",
        "            is_query=True,\n",
        "            show_progress_bar=True\n",
        "        )\n",
        "\n",
        "        # Retrieve Top Documents\n",
        "        top_k_initial = 15\n",
        "        initial_results = retriever.retrieve(queries_embeddings=query_embedding, k=top_k_initial)\n",
        "        retrieved_doc_ids = [result['id'] for result in initial_results[0]]\n",
        "\n",
        "        # Filter documents by company (if specified in query)\n",
        "        company = None\n",
        "        if 'quantumcore' in query.lower():\n",
        "            company = 'QuantumCore'\n",
        "        elif 'neocompute' in query.lower():\n",
        "            company = 'NeoCompute'\n",
        "        if company:\n",
        "            retrieved_doc_ids = [doc_id for doc_id in retrieved_doc_ids if document_sources.get(doc_id) == company]\n",
        "        retrieved_documents = [document_map[doc_id] for doc_id in retrieved_doc_ids]\n",
        "\n",
        "        # Rerank Documents\n",
        "        reranked_results = rank.rerank(\n",
        "            documents_ids=[retrieved_doc_ids],\n",
        "            queries_embeddings=query_embedding,\n",
        "            documents_embeddings=[model.encode(retrieved_documents, is_query=False)]\n",
        "        )\n",
        "\n",
        "        # Get Reranked Documents\n",
        "        reranked_doc_ids = []\n",
        "        if reranked_results and isinstance(reranked_results[0], list):\n",
        "            for result in reranked_results[0]:\n",
        "                if isinstance(result, dict) and 'id' in result:\n",
        "                    reranked_doc_ids.append(result['id'])\n",
        "                elif isinstance(result, str):\n",
        "                    reranked_doc_ids.append(result)\n",
        "        else:\n",
        "            reranked_doc_ids = retrieved_doc_ids\n",
        "\n",
        "        reranked_documents = [document_map[doc_id] for doc_id in reranked_doc_ids]\n",
        "\n",
        "        # Create Context\n",
        "        max_context_length = 600\n",
        "        context = '\\n'.join(reranked_documents[:3])[:max_context_length]\n",
        "        prompt_text = PROMPT.format(context=context, question=query)\n",
        "\n",
        "        # Generate Answer\n",
        "        response = generator(prompt_text)[0]['generated_text']\n",
        "        answer = response.strip()\n",
        "\n",
        "        # Post-processing\n",
        "        non_product_terms = {'Compliance', 'Cooling', 'Features', 'Storage', 'Networking', 'Frameworks', 'Uptime', 'Encryption'}\n",
        "        if any(role in query.lower() for role in ['ceo', 'cto', 'cfo']):\n",
        "            role = next((r for r in ['CEO', 'CTO', 'CFO'] if r.lower() in query.lower()), None)\n",
        "            if role:\n",
        "                match = re.search(rf'- ([^,]+?),\s*{role}\s*:', context, re.IGNORECASE)\n",
        "                if match:\n",
        "                    answer = match.group(1).strip()\n",
        "                else:\n",
        "                    answer = 'The answer could not be found in the text.'\n",
        "        elif 'product' in query.lower():\n",
        "            product_names = re.findall(r'- (\w+): (?:Quantum|Cloud-based|processing unit|platform)', context, re.IGNORECASE)\n",
        "            product_names = [name for name in product_names if name not in non_product_terms]\n",
        "            if product_names:\n",
        "                answer = ', '.join(sorted(set(product_names)))\n",
        "            else:\n",
        "                answer = 'The answer could not be found in the text.'\n",
        "        elif ', ' in answer:  # Handle comma-separated lists (e.g., compliance standards)\n",
        "            items = set(answer.split(', '))\n",
        "            items = [item for item in items if item not in non_product_terms]\n",
        "            answer = ', '.join(sorted(items)) if items else 'The answer could not be found in the text.'\n",
        "\n",
        "        # Debug logging (commented out)\n",
        "        # print(f'Debug: Query={query}, Context={context[:100]}..., Raw Answer={response}, Final Answer={answer}')\n",
        "\n",
        "        return context, answer\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f'Error processing query: {e}')\n",
        "        return None, 'Error processing query.'"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}